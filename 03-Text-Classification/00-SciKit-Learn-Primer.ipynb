{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Primer\n",
    "\n",
    "**Scikit-learn** (http://scikit-learn.org/) is an open-source machine learning library for Python that offers a variety of regression, classification and clustering algorithms.\n",
    "\n",
    "In this section we'll perform a fairly simple classification exercise with scikit-learn. In the next section we'll leverage the machine learning strength of scikit-learn to perform natural language classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation and Setup\n",
    "\n",
    "### From the command line or terminal:\n",
    "> `conda install scikit-learn`\n",
    "> <br>*or*<br>\n",
    "> `pip install -U scikit-learn`\n",
    "\n",
    "Scikit-learn additionally requires that NumPy and SciPy be installed. For more info visit http://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Imports and Load Data\n",
    "For this exercise we'll be using the **SMSSpamCollection** dataset from [UCI datasets](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) that contains more than 5 thousand SMS phone messages.<br>You can check out the [**sms_readme**](../TextFiles/sms_readme.txt) file for more info.\n",
    "\n",
    "The file is a [tab-separated-values](https://en.wikipedia.org/wiki/Tab-separated_values) (tsv) file with four columns:\n",
    "> **label** - every message is labeled as either ***ham*** or ***spam***<br>\n",
    "> **message** - the message itself<br>\n",
    "> **length** - the number of characters in each message<br>\n",
    "> **punct** - the number of punctuation characters in each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../TextFiles/smsspamcollection.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values:\n",
    "Machine learning models usually require complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a quick look at the *ham* and *spam* `label` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>We see that 4825 out of 5572 messages, or 86.6%, are ham.<br>This means that any machine learning model we create has to perform **better than 86.6%** to beat random chance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data:\n",
    "Since we're not ready to do anything with the message text, let's see if we can predict ham/spam labels based on message length and punctuation counts. We'll look at message `length` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This dataset is extremely skewed. The mean value is 80.5 and yet the max length is 910. Let's plot this on a logarithmic x-axis.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWhklEQVR4nO3de5BcZZ3G8e9DHBMvKJcMqTATnWgFKwlThHKcwEqVKEjGC4arG3alkpUlaAUWvIZYVsFqpYpFgfWyIuFSxF0kpACXAIoLEVCq0DBhI8kkshnNrLRJJWMUDSrZZPjtH3MS2qR7pnv6NvPO86ma6u73vOf0b/Kmnz7z9ulzFBGYmVlajmh0AWZmVn0OdzOzBDnczcwS5HA3M0uQw93MLEEOdzOzBL2m0QUATJ48Odra2hpdhpnZmLJ+/frfRkRzoWWjItzb2tro7u5udBlmZmOKpP8ttszTMmZmCXK4m5klqORwlzRB0n9Leih7fIykRyVtzW6Pzuu7TFKvpOclzatF4WZmVlw5c+5XAluAN2WPrwbWRsR1kq7OHi+VNAtYAMwGjgcek3RCRAxUsW4zG4f27dtHLpfj5ZdfbnQpdTVp0iRaW1tpamoqeZ2Swl1SK/AhYDnw6ax5PnB6dn8l8ASwNGtfFRF7gW2SeoFO4OmSqzIzKyCXy3HkkUfS1taGpEaXUxcRwe7du8nlckyfPr3k9UqdlvlX4PPAK3ltUyJiR/bkO4DjsvYW4IW8frmszcysIi+//DLHHnvsuAl2AEkce+yxZf+1Mmy4S/owsCsi1pdaS4G2w84rLGmxpG5J3f39/SVu2szGu/EU7AeM5HcuZc/93cBHJPUBq4D3SfoPYKekqdkTTwV2Zf1zwLS89VuB7YduNCJWRERHRHQ0Nxc8Bt/MbNTp6+vjxBNPbHQZwxp2zj0ilgHLACSdDnw2Ij4m6SvAQuC67PaBbJU1wHcl3cjgB6ozgHVVr9xsFDn7G08VbH/witPqXMn4UuzffaRSGq9KjnO/Dni/pK3A+7PHREQPsBrYDDwCLPGRMmaWkoGBAS699FJmz57NWWedxV/+8hduvfVW3vWud3HSSSdx/vnn8+c//xmARYsW8clPfpL3vve9vO1tb+PJJ5/k4x//ODNnzmTRokU1q7GscI+IJyLiw9n93RFxRkTMyG5/l9dveUS8PSLeERE/qHbRZmaNtHXrVpYsWUJPTw9HHXUU9913H+eddx7PPPMMP//5z5k5cya33377wf6///3v+dGPfsRNN93E2Wefzac+9Sl6enrYuHEjGzZsqEmNo+LcMmap8nRNmqZPn86cOXMAeOc730lfXx+bNm3ii1/8Ii+++CIvvfQS8+a9+v3Ns88+G0m0t7czZcoU2tvbAZg9ezZ9fX0Ht1VNPv2AmVmZJk6cePD+hAkT2L9/P4sWLeKb3/wmGzdu5JprrvmrQxcP9D/iiCP+at0jjjiC/fv316RGh7uZWRXs2bOHqVOnsm/fPu66665Gl+NpGTOzavjyl7/M3Llzeetb30p7ezt79uxpaD2KOOz7RXXX0dERPp+7jWXlHpLnOfeR2bJlCzNnzmx0GQ1R6HeXtD4iOgr197SMmVmCHO5mZglyuJuZJcjhbmaWIIe7mVmCHO5mZglyuJuZJchfYjKzseuW91R3e5c9Wd3tNZD33M3MSvSnP/2JD33oQ5x00kmceOKJ3HPPPbS1tbF06VI6Ozvp7Oykt7cXgAcffJC5c+dy8sknc+aZZ7Jz504Arr32WhYuXMhZZ51FW1sb999/P5///Odpb2+nq6uLffv2VaVW77mblaHaF4ewseWRRx7h+OOP5+GHHwbgD3/4A0uXLuVNb3oT69at4zvf+Q5XXXUVDz30EKeddho//elPkcRtt93G9ddfzw033ADAL3/5Sx5//HE2b97Mqaeeyn333cf111/Pueeey8MPP8w555xTca3eczczK1F7ezuPPfYYS5cu5Sc/+QlvfvObAbjooosO3j799NMA5HI55s2bR3t7O1/5ylfo6ek5uJ0PfOADNDU10d7ezsDAAF1dXQe339fXV5VaHe5mZiU64YQTWL9+Pe3t7SxbtowvfelLwF9fwPrA/SuuuILLL7+cjRs3cssttxQ9BXBTU9PBdap5CmCHu5lZibZv387rX/96Pvaxj/HZz36WZ599FoB77rnn4O2pp54KDE7ZtLS0ALBy5cq61zrsnLukScCPgYlZ/3sj4hpJ1wKXAv1Z1y9ExPezdZYBlwADwD9FxA9rULuZWV1t3LiRz33ucwf3uG+++WYuuOAC9u7dy9y5c3nllVe4++67gcEPTi+88EJaWlo45ZRT2LZtW11rHfaUvxr8e+ENEfGSpCbgKeBKoAt4KSK+ekj/WcDdQCdwPPAYcMJQF8n2KX9trKjWB6o+5e/IjMZT/ra1tdHd3c3kyZNr+jxVP+VvDHope9iU/Qz1jjAfWBUReyNiG9DLYNCbmVmdlDTnLmmCpA3ALuDRiPhZtuhySc9JukPS0VlbC/BC3uq5rO3QbS6W1C2pu7+//9DFZmZjQl9fX8332keipHCPiIGImAO0Ap2STgRuBt4OzAF2ADdk3VVoEwW2uSIiOiKio7m5eQSlm5lZMWUdLRMRLwJPAF0RsTML/VeAW3l16iUHTMtbrRXYXnmpZmYwGi4NWm8j+Z2HDXdJzZKOyu6/DjgT+IWkqXndzgU2ZffXAAskTZQ0HZgBrCu7MjOzQ0yaNIndu3ePq4CPCHbv3s2kSZPKWq+U0w9MBVZKmsDgm8HqiHhI0r9LmsPglEsfcFlWSI+k1cBmYD+wZKgjZczMStXa2koul2O8fU43adIkWltby1pn2HCPiOeAkwu0XzzEOsuB5WVVYmY2jKamJqZPn97oMsYEf0PVzCxBPiukjVtDfSHJXzKysc577mZmCXK4m5klyNMyZgX4ohw21nnP3cwsQQ53M7MEOdzNzBLkcDczS5DD3cwsQQ53M7MEOdzNzBLkcDczS5C/xGTJ8xeSbDxyuJs1wEjecHwyMyuHp2XMzBLkcDczS1Ap11CdJGmdpJ9L6pH0z1n7MZIelbQ1uz06b51lknolPS9pXi1/ATMzO1wpe+57gfdFxEnAHKBL0inA1cDaiJgBrM0eI2kWsACYDXQB38quv2pmZnVSyjVUA3gpe9iU/QQwHzg9a18JPAEszdpXRcReYJukXqATeLqahZuNN8U+hPUHrVZISXPukiZI2gDsAh6NiJ8BUyJiB0B2e1zWvQV4IW/1XNZ26DYXS+qW1D3ermRuZlZrJYV7RAxExBygFeiUdOIQ3VVoEwW2uSIiOiKio7m5uaRizcysNGUdLRMRLzI4/dIF7JQ0FSC73ZV1ywHT8lZrBbZXWqiZmZWulKNlmiUdld1/HXAm8AtgDbAw67YQeCC7vwZYIGmipOnADGBdles2M7MhlPIN1anAyuyIlyOA1RHxkKSngdWSLgF+DVwIEBE9klYDm4H9wJKIGKhN+WZmVkgpR8s8B5xcoH03cEaRdZYDyyuuzsxGt1veU7j9sifrW4cdxt9QNTNLkMPdzCxBDnczswQ53M3MEuRwNzNLkC/WYTbG+ZwzVoj33M3MEuRwNzNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPdzCxBPs7dzIZV9Fj619a5ECuZ99zNzBLkcDczS5CnZcxsWDe+eGXhBce9sb6FWMlKuYbqNEmPS9oiqUfSlVn7tZJ+I2lD9vPBvHWWSeqV9LykebX8BczM7HCl7LnvBz4TEc9KOhJYL+nRbNlNEfHV/M6SZgELgNnA8cBjkk7wdVTNzOpn2D33iNgREc9m9/cAW4CWIVaZD6yKiL0RsQ3oBTqrUayZmZWmrA9UJbUxeLHsn2VNl0t6TtIdko7O2lqAF/JWy1HgzUDSYkndkrr7+/vLr9zMzIoqOdwlvRG4D7gqIv4I3Ay8HZgD7ABuONC1wOpxWEPEiojoiIiO5ubmcus2M7MhlBTukpoYDPa7IuJ+gIjYGREDEfEKcCuvTr3kgGl5q7cC26tXspmZDWfYD1QlCbgd2BIRN+a1T42IHdnDc4FN2f01wHcl3cjgB6ozgHVVrdrMaqLYN1FvLNhqo1kpR8u8G7gY2ChpQ9b2BeAiSXMYnHLpAy4DiIgeSauBzQweabPER8qYmdXXsOEeEU9ReB79+0OssxxYXkFdZmZWAZ9+wMwsQQ53M7MEOdzNzBLkcDczS5DD3cwsQQ53M7MEOdzNzBLkcDczS5DD3cwsQb7MnpmN2NZdLxVsn1HnOuxw3nM3M0uQw93MLEEOdzOzBDnczcwS5A9UzRJV7MIbAA9ecVodK7FGcLibjUNDBb+lwdMyZmYJGjbcJU2T9LikLZJ6JF2ZtR8j6VFJW7Pbo/PWWSapV9LzkubV8hcwM7PDlbLnvh/4TETMBE4BlkiaBVwNrI2IGcDa7DHZsgXAbKAL+JakCbUo3szMChs23CNiR0Q8m93fA2wBWoD5wMqs20rgnOz+fGBVROyNiG1AL9BZ5brNzGwIZc25S2oDTgZ+BkyJiB0w+AYAHJd1awFeyFstl7Uduq3Fkroldff394+gdDMzK6bkcJf0RuA+4KqI+ONQXQu0xWENESsioiMiOpqbm0stw8zMSlBSuEtqYjDY74qI+7PmnZKmZsunAruy9hwwLW/1VmB7dco1M7NSlHK0jIDbgS0RcWPeojXAwuz+QuCBvPYFkiZKms7gCeLWVa9kMzMbTilfYno3cDGwUdKGrO0LwHXAakmXAL8GLgSIiB5Jq4HNDB5psyQiBqpduJmZFTdsuEfEUxSeRwc4o8g6y4HlFdRlZmYV8DdUzcwS5HA3M0uQw93MLEEOdzOzBDnczcwS5HA3M0uQw93MLEEOdzOzBDnczcwS5HA3M0uQw93MLEEOdzOzBDnczcwS5HA3M0uQw93MLEEOdzOzBDnczcwSVMo1VO+QtEvSpry2ayX9RtKG7OeDecuWSeqV9LykebUq3MzMiitlz/1OoKtA+00RMSf7+T6ApFnAAmB2ts63JE2oVrFmZlaaYcM9In4M/K7E7c0HVkXE3ojYBvQCnRXUZ2ZmI1DJnPvlkp7Lpm2OztpagBfy+uSyNjMzq6ORhvvNwNuBOcAO4IasXQX6RqENSFosqVtSd39//wjLMDOzQkYU7hGxMyIGIuIV4FZenXrJAdPyurYC24tsY0VEdERER3Nz80jKMDOzIkYU7pKm5j08FzhwJM0aYIGkiZKmAzOAdZWVaGZm5XrNcB0k3Q2cDkyWlAOuAU6XNIfBKZc+4DKAiOiRtBrYDOwHlkTEQE0qNzOzooYN94i4qEDz7UP0Xw4sr6QoMzOrjL+hamaWIIe7mVmCHO5mZglyuJuZJcjhbmaWIIe7mVmCHO5mZglyuJuZJcjhbmaWIIe7mVmCHO5mZglyuJuZJcjhbmaWIIe7mVmCHO5mZglyuJuZJcjhbmaWoGHDXdIdknZJ2pTXdoykRyVtzW6Pzlu2TFKvpOclzatV4WZmVlwpe+53Al2HtF0NrI2IGcDa7DGSZgELgNnZOt+SNKFq1ZqZWUmGDfeI+DHwu0Oa5wMrs/srgXPy2ldFxN6I2Ab0Ap3VKdXMzEo10jn3KRGxAyC7PS5rbwFeyOuXy9rMzKyOqv2Bqgq0RcGO0mJJ3ZK6+/v7q1yGmdn4NtJw3ylpKkB2uytrzwHT8vq1AtsLbSAiVkRER0R0NDc3j7AMMzMrZKThvgZYmN1fCDyQ175A0kRJ04EZwLrKSjQzs3K9ZrgOku4GTgcmS8oB1wDXAaslXQL8GrgQICJ6JK0GNgP7gSURMVCj2s3MrIhhwz0iLiqy6Iwi/ZcDyyspyszMKuNvqJqZJcjhbmaWIIe7mVmCHO5mZglyuJuZJcjhbmaWIIe7mVmCHO5mZglyuJuZJcjhbmaWIIe7mVmChj23jJmNHze+eGWjS7Aq8Z67mVmCHO5mZglyuJuZJcjhbmaWIIe7mVmCKjpaRlIfsAcYAPZHRIekY4B7gDagD/hoRPy+sjLNzKwc1dhzf29EzImIjuzx1cDaiJgBrM0em5lZHdViWmY+sDK7vxI4pwbPYWZmQ6g03AP4L0nrJS3O2qZExA6A7Pa4Cp/DzMzKVOk3VN8dEdslHQc8KukXpa6YvRksBnjLW95SYRlmZpavonCPiO3Z7S5J3wM6gZ2SpkbEDklTgV1F1l0BrADo6OiISuowAzj7G081uoQxo9anGRhqLB684rSaPrcNGvG0jKQ3SDrywH3gLGATsAZYmHVbCDxQaZFmZlaeSvbcpwDfk3RgO9+NiEckPQOslnQJ8GvgwsrLNDOzcow43CPiV8BJBdp3A2dUUpSZmVXG31A1M0uQw93MLEEOdzOzBDnczcwS5HA3M0uQw93MLEEOdzOzBDnczcwSVOmJw8zqzueQGV+KjbfPUTM0h7uZ1ZXDuj4c7mY2KvgvsupyuFtD+QVtVhsOd7Mxotg52D991NfK6m/jg8PdzMYkz90PzeFuNsZ5D90KcbgnaDTu0Xhu3ay+HO42outdjsY3kNGo3Hlyq63x9P/W4V5n4+k/l1kj+K/EQTULd0ldwNeACcBtEXFdrZ4rZY2+irxfKPWXwhz6UL+D/2qpj5qEu6QJwL8B7wdywDOS1kTE5lo8X601OmCrpR5BnfqbQQrBa6Uby39p12rPvRPozS6ijaRVwHxgTIa71c5I9vCqdbz3UHuQtQ7x8fwmMRo/hyh3p6SaOzG1eqNQRFR/o9IFQFdE/GP2+GJgbkRcntdnMbA4e/gO4PkCm3oz8IcS2iYDv61C6eUqVEu9tlPqOsP1G2p5sWWjfVygcWNTrXEZqk+l7eNxXMpZZyy9Zt4aEc0Fl0RE1X+ACxmcZz/w+GLgGyPYzooS27pr8XuMpL56bafUdYbrN9TyYstG+7g0cmyqNS7l/vuX0z4ex6WaYzNWXjO1Op97DpiW97gV2D6C7TxYYlujVKuWkWyn1HWG6zfU8mLLRvu4QOPGplrjMlSfarU3gl8zpT9PRWo1LfMa4H+AM4DfAM8AfxcRPVV/ssHn646Ijlps20bO4zI6eVxGr2qOTU0+UI2I/ZIuB37I4KGQd9Qq2DMrarhtGzmPy+jkcRm9qjY2NdlzNzOzxvI1VM3MEuRwNzNLkMPdzCxByYW7pDdIWinpVkl/3+h67FWS3ibpdkn3NroWe5Wkc7LXywOSzmp0PTZI0kxJ35Z0r6RPlrv+mAh3SXdI2iVp0yHtXZKel9Qr6eqs+Tzg3oi4FPhI3YsdZ8oZm4j4VURc0phKx5cyx+U/s9fLIuBvG1DuuFHmuGyJiE8AHwXKPjxyTIQ7cCfQld+Qd3KyDwCzgIskzWLwC1MvZN0G6ljjeHUnpY+N1c+dlD8uX8yWW+3cSRnjIukjwFPA2nKfaEyEe0T8GPjdIc0HT04WEf8HHDg5WY7BgIcx8vuNZWWOjdVJOeOiQf8C/CAinq13reNJua+XiFgTEX8DlD3FPJbDr4VX99BhMNRbgPuB8yXdzOj62vV4UnBsJB0r6dvAyZKWNaa0ca3Ya+YK4EzgAkmfaERh41yx18vpkr4u6Rbg++VudCxfiUkF2iIi/gT8Q72Lsb9SbGx2Aw6Pxik2Ll8Hvl7vYuygYuPyBPDESDc6lvfcq3VyMqs+j83o5HEZnWoyLmM53J8BZkiaLum1wAJgTYNrskEem9HJ4zI61WRcxkS4S7obeBp4h6ScpEsiYj9w4ORkW4DVNT45mRXgsRmdPC6jUz3HxScOMzNL0JjYczczs/I43M3MEuRwNzNLkMPdzCxBDnczswQ53M3MEuRwNzNLkMPdzCxBDnczswT9P49TLhHO7xydAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>It looks like there's a small range of values where a message is more likely to be spam than ham.</font>\n",
    "\n",
    "Now let's look at the `punct` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean        4.177495\n",
       "std         4.623919\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         6.000000\n",
       "max       133.000000\n",
       "Name: punct, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "bins = 1.5**(np.arange(0,15))\n",
    "plt.hist(df[df['label']=='ham']['punct'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['punct'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This looks even worse - there seem to be no values where one would pick spam over ham. We'll still try to build a machine learning classification model, but we should expect poor results.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Split the data into train & test sets:\n",
    "\n",
    "If we wanted to divide the DataFrame into two smaller sets, we could use\n",
    "> `train, test = train_test_split(df)`\n",
    "\n",
    "For our purposes let's also set up our Features (X) and Labels (y). The Label is simple - we're trying to predict the `label` column in our data. For Features we'll use the `length` and `punct` columns. *By convention, **X** is capitalized and **y** is lowercase.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "There are two ways to build a feature set from the columns we want. If the number of features is small, then we can pass those in directly:\n",
    "> `X = df[['length','punct']]`\n",
    "\n",
    "If the number of features is large, then it may be easier to drop the Label and any other unwanted columns:\n",
    "> `X = df.drop(['label','message'], axis=1)`\n",
    "\n",
    "These operations make copies of **df**, but do not change the original DataFrame in place. All the original data is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Feature and Label sets\n",
    "X = df[['length','punct']]  # note the double set of brackets\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional train/test/split arguments:\n",
    "The default test size for `train_test_split` is 30%. Here we'll assign 33% of the data for testing.<br>\n",
    "Also, we can set a `random_state` seed value to ensure that everyone uses the same \"random\" training & testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (3733, 2)\n",
      "Testing Data Shape:  (1839, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print('Training Data Shape:', X_train.shape)\n",
    "print('Testing Data Shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass these sets into a series of different training & testing algorithms and compare their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a Logistic Regression classifier\n",
    "One of the simplest multi-class classification tools is [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Scikit-learn offers a variety of algorithmic solvers; we'll use [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1547   46]\n",
      " [ 241    5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Create a prediction set:\n",
    "predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1547</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>241</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1547    46\n",
       "spam   241     5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can make the confusion matrix less confusing by adding labels:\n",
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>These results are terrible! More spam messages were confused as ham (241) than correctly identified as spam (5), although a relatively small number of ham messages (46) were confused as spam.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.92      1593\n",
      "        spam       0.10      0.02      0.03       246\n",
      "\n",
      "    accuracy                           0.84      1839\n",
      "   macro avg       0.48      0.50      0.47      1839\n",
      "weighted avg       0.76      0.84      0.80      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.843936922240348\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This model performed *worse* than a classifier that assigned all messages as \"ham\" would have!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a naïve Bayes classifier:\n",
    "One of the most common - and successful - classifiers is [naïve Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1583   10]\n",
      " [ 246    0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = nb_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>The total number of confusions dropped from **287** to **256**. [241+46=287, 246+10=256]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.93      1593\n",
      "        spam       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.86      1839\n",
      "   macro avg       0.43      0.50      0.46      1839\n",
      "weighted avg       0.75      0.86      0.80      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607939097335509\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>Better, but still less accurate than 86.6%</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a support vector machine (SVM) classifier\n",
    "Among the SVM options available, we'll use [C-Support Vector Classification (SVC)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(gamma='auto')\n",
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1515   78]\n",
      " [ 131  115]]\n"
     ]
    }
   ],
   "source": [
    "predictions = svc_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>The total number of confusions dropped even further to **209**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.94      1593\n",
      "        spam       0.60      0.47      0.52       246\n",
      "\n",
      "    accuracy                           0.89      1839\n",
      "   macro avg       0.76      0.71      0.73      1839\n",
      "weighted avg       0.88      0.89      0.88      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8863512778684067\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>And finally we have a model that performs *slightly* better than random chance.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now you should be able to load a dataset, divide it into training and testing sets, and perform simple analyses using scikit-learn.\n",
    "## Next up: Feature Extraction from Text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
